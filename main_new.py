"""
Main script cho Few-Shot Learning vá»›i cáº¥u trÃºc modular
"""
import torch
import json
import os
from datetime import datetime

# Import cÃ¡c module
from utils.config_loader import load_config, print_config_summary
from utils.transforms import create_transforms
from models.backbone import RelationNetworkModel
from data.dataset import FewShotDataset
from analysis.dataset_analysis import analyze_and_visualize_dataset
from evaluation.metrics import calculate_detailed_metrics, print_detailed_evaluation_metrics
from visualization.plots import (
    plot_confusion_matrix, 
    analyze_accuracy_by_class, 
    plot_single_results
)
from training.episode_runner import run_multiple_episodes_with_detailed_evaluation

def save_config_to_output_folder(config, output_folder, aug_stats=None):
    """
    LÆ°u cáº¥u hÃ¬nh vÃ o file JSON trong folder káº¿t quáº£
    """
    config_file = os.path.join(output_folder, "config.json")
    
    # Táº¡o báº£n sao cá»§a config Ä‘á»ƒ loáº¡i bá» cÃ¡c object khÃ´ng thá»ƒ serialize
    config_to_save = {}
    for key, value in config.items():
        if isinstance(value, (str, int, float, bool, list, dict)):
            config_to_save[key] = value
        else:
            config_to_save[key] = str(value)  # Chuyá»ƒn thÃ nh string náº¿u khÃ´ng thá»ƒ serialize
    
    # ThÃªm timestamp
    config_to_save['timestamp'] = datetime.now().isoformat()
    config_to_save['output_folder'] = output_folder
    
    # ThÃªm thá»‘ng kÃª augmentation náº¿u cÃ³
    if aug_stats:
        config_to_save['augmentation_stats'] = aug_stats
    
    with open(config_file, 'w', encoding='utf-8') as f:
        json.dump(config_to_save, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ’¾ Cáº¥u hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o: {config_file}")

def calculate_augmentation_stats(config, dataset_info):
    """
    TÃ­nh toÃ¡n thá»‘ng kÃª vá» data augmentation
    """
    total_original_images = dataset_info['total_images']
    n_way = config['N_WAY']
    k_shot = config['K_SHOT']
    q_query = config['Q_QUERY']
    q_valid = config['Q_VALID'] if config['USE_VALIDATION'] else 0
    num_episodes = config['NUM_EPISODES']
    
    # Sá»‘ áº£nh gá»‘c Ä‘Æ°á»£c sá»­ dá»¥ng trong má»—i episode
    images_per_episode = n_way * (k_shot + q_query + q_valid)
    
    # Tá»•ng sá»‘ áº£nh gá»‘c Ä‘Æ°á»£c sá»­ dá»¥ng
    total_original_used = images_per_episode * num_episodes
    
    # TÃ­nh toÃ¡n hiá»‡u quáº£ augmentation
    # Má»—i áº£nh support (k_shot) sáº½ Ä‘Æ°á»£c augment
    augmented_images_per_episode = n_way * k_shot
    total_augmented_images = augmented_images_per_episode * num_episodes
    
    # Tá»•ng sá»‘ áº£nh sau augmentation (gá»‘c + augmented)
    total_images_after_aug = total_original_used + total_augmented_images
    
    # Tá»· lá»‡ augmentation
    augmentation_ratio = total_augmented_images / total_original_used if total_original_used > 0 else 0
    
    stats = {
        'total_original_images': total_original_images,
        'images_per_episode': images_per_episode,
        'total_original_used': total_original_used,
        'augmented_images_per_episode': augmented_images_per_episode,
        'total_augmented_images': total_augmented_images,
        'total_images_after_aug': total_images_after_aug,
        'augmentation_ratio': augmentation_ratio,
        'effective_dataset_size': total_images_after_aug
    }
    
    return stats

def print_augmentation_stats(aug_stats, config):
    """
    In thá»‘ng kÃª augmentation
    """
    print("\nğŸ“Š THá»NG KÃŠ DATA AUGMENTATION:")
    print("=" * 50)
    print(f"ğŸ“ˆ Tá»•ng áº£nh gá»‘c trong dataset: {aug_stats['total_original_images']:,}")
    print(f"ğŸ¯ áº¢nh sá»­ dá»¥ng má»—i episode: {aug_stats['images_per_episode']}")
    print(f"ğŸ“¦ Tá»•ng áº£nh gá»‘c Ä‘Æ°á»£c sá»­ dá»¥ng: {aug_stats['total_original_used']:,}")
    print(f"ğŸ”„ áº¢nh Ä‘Æ°á»£c augment má»—i episode: {aug_stats['augmented_images_per_episode']}")
    print(f"âœ¨ Tá»•ng áº£nh Ä‘Æ°á»£c augment: {aug_stats['total_augmented_images']:,}")
    print(f"ğŸ“Š Tá»•ng áº£nh sau augmentation: {aug_stats['total_images_after_aug']:,}")
    print(f"ğŸ“ˆ Tá»· lá»‡ augmentation: {aug_stats['augmentation_ratio']:.2%}")
    print(f"ğŸš€ KÃ­ch thÆ°á»›c dataset hiá»‡u quáº£: {aug_stats['effective_dataset_size']:,}")
    
    # ThÃ´ng tin chi tiáº¿t vá» augmentation
    aug_config = config['AUGMENTATION_CONFIG']
    print(f"\nğŸ”§ Cáº¥u hÃ¬nh augmentation:")
    print(f"   - Random Crop: +{aug_config['random_crop_size']}px")
    print(f"   - Rotation: Â±{aug_config['rotation_degrees']}Â°")
    print(f"   - Horizontal Flip: {aug_config['flip_probability']:.1%}")
    print(f"   - Color Jitter: Brightness={aug_config['color_jitter']['brightness']}, "
          f"Contrast={aug_config['color_jitter']['contrast']}, "
          f"Saturation={aug_config['color_jitter']['saturation']}, "
          f"Hue={aug_config['color_jitter']['hue']}")
    print(f"   - Grayscale: {aug_config['grayscale_probability']:.1%}")
    
    print("=" * 50)

def main():
    """
    Main function
    """
    print("ğŸš€ Khá»Ÿi táº¡o Few-Shot Learning vá»›i Data Augmentation")
    print("=" * 60)
    
    # Load cáº¥u hÃ¬nh
    config = load_config()
    print_config_summary(config)
    
    # LÆ°u cáº¥u hÃ¬nh vÃ o folder káº¿t quáº£ (sáº½ cáº­p nháº­t sau khi cÃ³ aug_stats)
    save_config_to_output_folder(config, config['OUTPUT_FOLDER'])
    
    # Thiáº¿t láº­p device
    DEVICE = 'cuda' if torch.cuda.is_available() and config['USE_CUDA'] else 'cpu'
    config['DEVICE'] = DEVICE
    
    # PhÃ¢n tÃ­ch vÃ  váº½ Ä‘á»“ thá»‹ dataset
    print("ğŸ“ˆ PHÃ‚N TÃCH DATASET:")
    if config['DETAILED_ANALYSIS']:
        print("ğŸ” Cháº¡y phÃ¢n tÃ­ch chi tiáº¿t...")
        dataset_info = analyze_and_visualize_dataset(config['DATASET_PATH'], config)
    else:
        print("ğŸ” Cháº¡y phÃ¢n tÃ­ch cÆ¡ báº£n...")
        dataset_info = analyze_and_visualize_dataset(config['DATASET_PATH'], config)
    
    if dataset_info is None:
        print("âŒ KhÃ´ng thá»ƒ phÃ¢n tÃ­ch dataset. ThoÃ¡t chÆ°Æ¡ng trÃ¬nh.")
        exit()
    
    # Kiá»ƒm tra xem dataset cÃ³ Ä‘á»§ dá»¯ liá»‡u cho few-shot learning khÃ´ng
    if dataset_info['total_images'] < config['N_WAY'] * (config['K_SHOT'] + config['Q_QUERY']):
        print(f"âš ï¸ Cáº£nh bÃ¡o: Dataset cÃ³ thá»ƒ khÃ´ng Ä‘á»§ dá»¯ liá»‡u cho {config['N_WAY']}-way {config['K_SHOT']}-shot learning")
        print(f"   Cáº§n Ã­t nháº¥t {config['N_WAY'] * (config['K_SHOT'] + config['Q_QUERY'])} áº£nh, hiá»‡n cÃ³ {dataset_info['total_images']} áº£nh")
    
    # TÃ­nh toÃ¡n vÃ  hiá»ƒn thá»‹ thá»‘ng kÃª augmentation
    aug_stats = calculate_augmentation_stats(config, dataset_info)
    print_augmentation_stats(aug_stats, config)
    
    # Cáº­p nháº­t config vá»›i thá»‘ng kÃª augmentation
    save_config_to_output_folder(config, config['OUTPUT_FOLDER'], aug_stats)
    
    print("\n" + "=" * 60)
    
    # Táº¡o transforms
    transform_basic, transform_augmented, transform_inference = create_transforms(config)
    
    # Khá»Ÿi táº¡o dataset vá»›i data augmentation
    fewshot_data = FewShotDataset(
        config['DATASET_PATH'], 
        transform_train=transform_augmented,
        transform_test=transform_basic
    )
    
    # Khá»Ÿi táº¡o model
    model = RelationNetworkModel(embed_dim=config['EMBED_DIM'], relation_dim=config['RELATION_DIM']).to(DEVICE)
    print(f"âœ… Relation Network Model Ä‘Ã£ Ä‘Æ°á»£c táº£i lÃªn {DEVICE}")
    print(f"ğŸ“Š Cáº¥u hÃ¬nh: {config['N_WAY']}-way, {config['K_SHOT']}-shot, {config['Q_QUERY']}-query")
    print(f"ğŸ§  Kiáº¿n trÃºc: Vision Transformer + Relation Network (CNN)")
    print("=" * 60)

    # Cháº¡y episodes vá»›i Relation Network
    print(f"\nğŸ¯ CHáº Y {config['NUM_EPISODES']} EPISODES Vá»šI RELATION NETWORK:")
    results_with_aug = run_multiple_episodes_with_detailed_evaluation(
        model, fewshot_data, config, config['NUM_EPISODES'], 
        use_augmentation=True, include_validation=config['USE_VALIDATION']
    )
    
    print(f"\nğŸ“Š Káº¾T QUáº¢ Vá»šI RELATION NETWORK:")
    print(f"   Query Accuracy trung bÃ¬nh: {results_with_aug['avg_query_acc']:.4f} Â± {results_with_aug['std_query_acc']:.4f}")
    print(f"   Query Loss trung bÃ¬nh: {results_with_aug['avg_query_loss']:.4f} Â± {results_with_aug['std_query_loss']:.4f}")
    print(f"   Query Accuracy min/max: {results_with_aug['min_query_acc']:.4f} / {results_with_aug['max_query_acc']:.4f}")
    
    if 'avg_valid_acc' in results_with_aug:
        print(f"   Validation Accuracy trung bÃ¬nh: {results_with_aug['avg_valid_acc']:.4f} Â± {results_with_aug['std_valid_acc']:.4f}")
        print(f"   Validation Loss trung bÃ¬nh: {results_with_aug['avg_valid_loss']:.4f} Â± {results_with_aug['std_valid_loss']:.4f}")
        print(f"   Validation Accuracy min/max: {results_with_aug['min_valid_acc']:.4f} / {results_with_aug['max_valid_acc']:.4f}")
        
        # So sÃ¡nh Query vs Validation
        acc_diff = results_with_aug['avg_query_acc'] - results_with_aug['avg_valid_acc']
        print(f"   ChÃªnh lá»‡ch Query-Validation Accuracy: {acc_diff:.4f}")
        if acc_diff > 0.05:
            print(f"   âš ï¸ CÃ³ thá»ƒ bá»‹ overfitting (Query > Validation)")
        elif acc_diff < -0.05:
            print(f"   âš ï¸ CÃ³ thá»ƒ bá»‹ underfitting (Query < Validation)")
        else:
            print(f"   âœ… MÃ´ hÃ¬nh cÃ¢n báº±ng tá»‘t")
    
    # ==== ÄÃNH GIÃ CHI TIáº¾T QUERY SET ====
    print(f"\nğŸ” ÄÃNH GIÃ CHI TIáº¾T QUERY SET:")
    query_predictions = results_with_aug['all_query_predictions']
    query_targets = results_with_aug['all_query_targets']
    
    # Láº¥y tÃªn class thá»±c táº¿ tá»« dataset
    dataset_classes = fewshot_data.dataset.classes
    print(f"ğŸ“‹ CÃ¡c class cÃ³ sáºµn trong dataset: {dataset_classes}")
    print(f"ğŸ¯ Sá»­ dá»¥ng {config['N_WAY']} class trong má»—i episode (chá»n ngáº«u nhiÃªn)")
    
    # Hiá»ƒn thá»‹ cÃ¡c class Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c episodes
    print(f"ğŸ“Š CÃ¡c class Ä‘Æ°á»£c sá»­ dá»¥ng trong {config['NUM_EPISODES']} episodes:")
    for i, episode_classes in enumerate(results_with_aug['all_episode_class_names']):
        print(f"   Episode {i+1}: {episode_classes}")
    
    # Sá»­ dá»¥ng tÃªn class thá»±c táº¿ tá»« episode cuá»‘i cÃ¹ng cho Ä‘Ã¡nh giÃ¡
    class_names = results_with_aug['all_episode_class_names'][-1]  # Láº¥y tÃªn class tá»« episode cuá»‘i
    
    # TÃ­nh metrics chi tiáº¿t
    query_metrics = calculate_detailed_metrics(query_predictions, query_targets, config['N_WAY'])
    
    # In metrics
    print_detailed_evaluation_metrics(query_metrics, class_names, "Query Set")
    
    # Váº½ confusion matrix
    if config['SAVE_RESULTS']:
        plot_confusion_matrix(query_metrics['confusion_matrix'], class_names, "query_confusion_matrix.png", config)
        analyze_accuracy_by_class(query_predictions, query_targets, class_names, "query_accuracy_by_class.png", config)
        # plot_imbalance_analysis(query_metrics, class_names, "query_imbalance_analysis.png", config)
    
    # ==== ÄÃNH GIÃ CHI TIáº¾T VALIDATION SET (náº¿u cÃ³) ====
    if 'all_valid_predictions' in results_with_aug:
        print(f"\nğŸ” ÄÃNH GIÃ CHI TIáº¾T VALIDATION SET:")
        valid_predictions = results_with_aug['all_valid_predictions']
        valid_targets = results_with_aug['all_valid_targets']
        
        # TÃ­nh metrics chi tiáº¿t
        valid_metrics = calculate_detailed_metrics(valid_predictions, valid_targets, config['N_WAY'])
        
        # In metrics (sá»­ dá»¥ng cÃ¹ng tÃªn class thá»±c táº¿)
        print_detailed_evaluation_metrics(valid_metrics, class_names, "Validation Set")
        
        # Váº½ confusion matrix
        if config['SAVE_RESULTS']:
            plot_confusion_matrix(valid_metrics['confusion_matrix'], class_names, "valid_confusion_matrix.png", config)
            analyze_accuracy_by_class(valid_predictions, valid_targets, class_names, "valid_accuracy_by_class.png", config)
            # plot_imbalance_analysis(valid_metrics, class_names, "valid_imbalance_analysis.png", config)
    
    # Váº½ Ä‘á»“ thá»‹ káº¿t quáº£ vá»›i augmentation
    if config['SAVE_RESULTS']:
        plot_single_results(results_with_aug, "episode_results_single.png", config)
    
    print("\nâœ… HoÃ n thÃ nh!")
    print(f"ğŸ“ Táº¥t cáº£ káº¿t quáº£ Ä‘Ã£ Ä‘Æ°á»£c lÆ°u trong folder: {config['OUTPUT_FOLDER']}")
    print(f"ğŸ’¾ Cáº¥u hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o: {config['OUTPUT_FOLDER']}/config.json")
    if not config.get('SHOW_PLOTS', False):
        print("ğŸ”‡ Cháº¿ Ä‘á»™ khÃ´ng hiá»ƒn thá»‹ áº£nh pop-up Ä‘Ã£ Ä‘Æ°á»£c báº­t (SHOW_PLOTS = False)")
    print("=" * 60)
    
    if config['DETAILED_ANALYSIS']:
        print(f"ğŸ“Š Äá»“ thá»‹ phÃ¢n tÃ­ch chi tiáº¿t: {config['OUTPUT_FOLDER']}/detailed_analysis.png")
        print(f"ğŸ“Š Äá»“ thá»‹ Ä‘á»‹nh dáº¡ng file: {config['OUTPUT_FOLDER']}/file_formats_analysis.png")
    else:
        print(f"ğŸ“Š Äá»“ thá»‹ phÃ¢n tÃ­ch cÆ¡ báº£n: {config['OUTPUT_FOLDER']}/dataset_analysis.png")
    
    if config['SAVE_RESULTS']:
            print(f"ğŸ“Š Äá»“ thá»‹ káº¿t quáº£ episodes: {config['OUTPUT_FOLDER']}/episode_results_single.png")
    print(f"ğŸ“Š Confusion matrix: {config['OUTPUT_FOLDER']}/query_confusion_matrix.png")
    print(f"ğŸ“Š Accuracy theo class: {config['OUTPUT_FOLDER']}/query_accuracy_by_class.png")
    # print(f"ğŸ“Š Imbalance analysis: {config['OUTPUT_FOLDER']}/query_imbalance_analysis.png")
    
    if config['USE_VALIDATION']:
        print(f"ğŸ“Š Validation confusion matrix: {config['OUTPUT_FOLDER']}/valid_confusion_matrix.png")
        print(f"ğŸ“Š Validation accuracy theo class: {config['OUTPUT_FOLDER']}/valid_accuracy_by_class.png")
        # print(f"ğŸ“Š Validation imbalance analysis: {config['OUTPUT_FOLDER']}/valid_imbalance_analysis.png")
    
    print(f"ğŸ§  PhÆ°Æ¡ng phÃ¡p: Relation Network (CNN) thay vÃ¬ Euclidean Distance")
    print(f"ğŸ“ˆ Relation scores: 0-1 (cao hÆ¡n = tÆ°Æ¡ng tá»± hÆ¡n)")
    
    print("=" * 60)

if __name__ == "__main__":
    main()
