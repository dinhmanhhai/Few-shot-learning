"""
Main script cho Few-Shot Learning vá»›i cáº¥u trÃºc modular
"""
import torch
import json
import os
from datetime import datetime

# Import cÃ¡c module
from utils.config_loader import load_config, print_config_summary
from utils.transforms import create_transforms
from models.backbone import FlexibleDistanceModel
from data.dataset import FewShotDataset
from analysis.dataset_analysis import analyze_and_visualize_dataset
from evaluation.metrics import calculate_detailed_metrics, print_detailed_evaluation_metrics
from visualization.plots import (
    plot_confusion_matrix, 
    analyze_accuracy_by_class, 
    plot_single_results
)
from training.episode_runner import run_multiple_episodes_with_detailed_evaluation
from utils.class_augmentation import ClassSpecificAugmentation

def save_config_to_output_folder(config, output_folder, aug_stats=None, model_info=None):
    """
    LÆ°u cáº¥u hÃ¬nh vÃ o file JSON trong folder káº¿t quáº£
    """
    config_file = os.path.join(output_folder, "config.json")
    
    # Táº¡o báº£n sao cá»§a config Ä‘á»ƒ loáº¡i bá» cÃ¡c object khÃ´ng thá»ƒ serialize
    config_to_save = {}
    for key, value in config.items():
        if isinstance(value, (str, int, float, bool, list, dict)):
            config_to_save[key] = value
        else:
            config_to_save[key] = str(value)  # Chuyá»ƒn thÃ nh string náº¿u khÃ´ng thá»ƒ serialize
    
    # ThÃªm timestamp
    config_to_save['timestamp'] = datetime.now().isoformat()
    config_to_save['output_folder'] = output_folder
    
    # ThÃªm thÃ´ng tin model náº¿u cÃ³
    if model_info:
        config_to_save['model_info'] = model_info
    
    # ThÃªm thá»‘ng kÃª augmentation náº¿u cÃ³
    if aug_stats:
        config_to_save['augmentation_stats'] = aug_stats
    
    with open(config_file, 'w', encoding='utf-8') as f:
        json.dump(config_to_save, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ’¾ Cáº¥u hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o: {config_file}")

def calculate_augmentation_stats(config, dataset_info):
    """
    TÃ­nh toÃ¡n thá»‘ng kÃª vá» data augmentation
    """
    total_original_images = dataset_info['total_images']
    n_way = config['N_WAY']
    k_shot = config['K_SHOT']
    q_query = config['Q_QUERY']
    q_valid = config['Q_VALID'] if config['USE_VALIDATION'] else 0
    num_episodes = config['NUM_EPISODES']
    
    # Sá»‘ áº£nh gá»‘c Ä‘Æ°á»£c sá»­ dá»¥ng trong má»—i episode
    images_per_episode = n_way * (k_shot + q_query + q_valid)
    
    # Tá»•ng sá»‘ áº£nh gá»‘c Ä‘Æ°á»£c sá»­ dá»¥ng
    total_original_used = images_per_episode * num_episodes
    
    # TÃ­nh toÃ¡n hiá»‡u quáº£ augmentation
    # Má»—i áº£nh support (k_shot) sáº½ Ä‘Æ°á»£c augment
    augmented_images_per_episode = n_way * k_shot
    total_augmented_images = augmented_images_per_episode * num_episodes
    
    # Tá»•ng sá»‘ áº£nh sau augmentation (gá»‘c + augmented)
    total_images_after_aug = total_original_used + total_augmented_images
    
    # Tá»· lá»‡ augmentation
    augmentation_ratio = total_augmented_images / total_original_used if total_original_used > 0 else 0
    
    stats = {
        'total_original_images': total_original_images,
        'images_per_episode': images_per_episode,
        'total_original_used': total_original_used,
        'augmented_images_per_episode': augmented_images_per_episode,
        'total_augmented_images': total_augmented_images,
        'total_images_after_aug': total_images_after_aug,
        'augmentation_ratio': augmentation_ratio,
        'effective_dataset_size': total_images_after_aug
    }
    
    return stats

def print_augmentation_stats(aug_stats, config):
    """
    In thá»‘ng kÃª augmentation
    """
    print("\nğŸ“Š THá»NG KÃŠ DATA AUGMENTATION:")
    print("=" * 50)
    print(f"ğŸ“ˆ Tá»•ng áº£nh gá»‘c trong dataset: {aug_stats['total_original_images']:,}")
    print(f"ğŸ¯ áº¢nh sá»­ dá»¥ng má»—i episode: {aug_stats['images_per_episode']}")
    # print(f"ğŸ“¦ Tá»•ng áº£nh gá»‘c Ä‘Æ°á»£c sá»­ dá»¥ng: {aug_stats['total_original_used']:,}")
    # print(f"ğŸ”„ áº¢nh Ä‘Æ°á»£c augment má»—i episode: {aug_stats['augmented_images_per_episode']}")
    # print(f"âœ¨ Tá»•ng áº£nh Ä‘Æ°á»£c augment: {aug_stats['total_augmented_images']:,}")
    # print(f"ğŸ“Š Tá»•ng áº£nh sau augmentation: {aug_stats['total_images_after_aug']:,}")
    # print(f"ğŸ“ˆ Tá»· lá»‡ augmentation: {aug_stats['augmentation_ratio']:.2%}")
    # print(f"ğŸš€ KÃ­ch thÆ°á»›c dataset hiá»‡u quáº£: {aug_stats['effective_dataset_size']:,}")
    
    # TÃ­nh toÃ¡n tá»•ng sá»‘ lÆ°á»£ng áº£nh cá»§a dataset sau augmentation
    total_dataset_after_aug = aug_stats['total_original_images'] + aug_stats['total_augmented_images']
    print(f"ğŸ“Š Tá»•ng sá»‘ lÆ°á»£ng áº£nh dataset sau augmentation: {total_dataset_after_aug:,}")
    print(f"ğŸ“ˆ Tá»· lá»‡ tÄƒng dataset: {(aug_stats['total_augmented_images']/aug_stats['total_original_images'])*100:.1f}%")
    
    # ThÃ´ng tin vá» config Ä‘Æ°á»£c sá»­ dá»¥ng
    print(f"\nâš™ï¸ Cáº¤U HÃŒNH FEW-SHOT LEARNING:")
    print(f"   â€¢ {config['N_WAY']}-way, {config['K_SHOT']}-shot, {config['Q_QUERY']}-query, {config['Q_VALID']}-valid")
    print(f"   â€¢ Sá»‘ episodes: {config['NUM_EPISODES']}")
    print(f"   â€¢ Tá»•ng áº£nh Ä‘Æ°á»£c sá»­ dá»¥ng: {aug_stats['total_original_used']:,} (gá»‘c) + {aug_stats['total_augmented_images']:,} (augment) = {aug_stats['total_images_after_aug']:,}")
    print(f"   â€¢ Tá»· lá»‡ sá»­ dá»¥ng dataset: {(aug_stats['total_images_after_aug']/total_dataset_after_aug)*100:.1f}%")
    
    # ThÃ´ng tin chi tiáº¿t vá» augmentation
    aug_config = config['AUGMENTATION_CONFIG']
    print(f"\nğŸ”§ Cáº¥u hÃ¬nh augmentation:")
    print(f"   - Random Crop: +{aug_config['random_crop_size']}px")
    print(f"   - Rotation: Â±{aug_config['rotation_degrees']}Â°")
    print(f"   - Horizontal Flip: {aug_config['flip_probability']:.1%}")
    print(f"   - Color Jitter: Brightness={aug_config['color_jitter']['brightness']}, "
          f"Contrast={aug_config['color_jitter']['contrast']}, "
          f"Saturation={aug_config['color_jitter']['saturation']}, "
          f"Hue={aug_config['color_jitter']['hue']}")
    print(f"   - Grayscale: {aug_config['grayscale_probability']:.1%}")
    
    print("=" * 50)

def main():
    """
    Main function
    """
    print("ğŸš€ Khá»Ÿi táº¡o Few-Shot Learning vá»›i Data Augmentation")
    print("=" * 60)
    
    # Load cáº¥u hÃ¬nh
    config = load_config()
    print_config_summary(config)
    
    # LÆ°u cáº¥u hÃ¬nh vÃ o folder káº¿t quáº£ (sáº½ cáº­p nháº­t sau khi cÃ³ model_info vÃ  aug_stats)
    save_config_to_output_folder(config, config['OUTPUT_FOLDER'])
    
    # Thiáº¿t láº­p device
    DEVICE = 'cuda' if torch.cuda.is_available() and config['USE_CUDA'] else 'cpu'
    config['DEVICE'] = DEVICE
    
    # PhÃ¢n tÃ­ch dataset
    print("ğŸ“ˆ PHÃ‚N TÃCH DATASET:")
    dataset_info = analyze_and_visualize_dataset(config['DATASET_PATH'], config)
    
    # Táº¡o Ä‘á»“ thá»‹ phÃ¢n bá»‘ class riÃªng biá»‡t
    print("ğŸ“Š Táº O Äá»’ THá»Š PHÃ‚N Bá» CLASS:")
    from analysis.dataset_analysis import create_class_distribution_chart
    class_dist_info = create_class_distribution_chart(config['DATASET_PATH'], config)
    
    if dataset_info is None:
        print("âŒ KhÃ´ng thá»ƒ phÃ¢n tÃ­ch dataset. ThoÃ¡t chÆ°Æ¡ng trÃ¬nh.")
        exit()
    
    # Debug: Kiá»ƒm tra class distribution
    print(f"ğŸ” Debug - Dataset info keys: {list(dataset_info.keys())}")
    if 'class_distribution' in dataset_info:
        print(f"ğŸ“Š Class distribution cÃ³ sáºµn: {len(dataset_info['class_distribution'])} classes")
        print(f"   Sample: {dict(list(dataset_info['class_distribution'].items())[:3])}")
    else:
        print("âš ï¸ KhÃ´ng cÃ³ class_distribution trong dataset_info")
        print("   CÃ³ thá»ƒ cáº§n cháº¡y DETAILED_ANALYSIS = True")
    
    # Kiá»ƒm tra xem dataset cÃ³ Ä‘á»§ dá»¯ liá»‡u cho few-shot learning khÃ´ng
    if dataset_info['total_images'] < config['N_WAY'] * (config['K_SHOT'] + config['Q_QUERY']):
        print(f"âš ï¸ Cáº£nh bÃ¡o: Dataset cÃ³ thá»ƒ khÃ´ng Ä‘á»§ dá»¯ liá»‡u cho {config['N_WAY']}-way {config['K_SHOT']}-shot learning")
        print(f"   Cáº§n Ã­t nháº¥t {config['N_WAY'] * (config['K_SHOT'] + config['Q_QUERY'])} áº£nh, hiá»‡n cÃ³ {dataset_info['total_images']} áº£nh")
    
    # TÃ­nh toÃ¡n vÃ  hiá»ƒn thá»‹ thá»‘ng kÃª augmentation
    if config.get('USE_AUGMENTATION', False):
        aug_stats = calculate_augmentation_stats(config, dataset_info)
        print_augmentation_stats(aug_stats, config)
        
        # Cáº­p nháº­t config vá»›i thá»‘ng kÃª augmentation (model_info sáº½ Ä‘Æ°á»£c thÃªm sau)
        save_config_to_output_folder(config, config['OUTPUT_FOLDER'], aug_stats)
        
        # Xá»­ lÃ½ class-specific augmentation
        if config.get('CLASS_AUGMENTATION', {}).get('enable_selective', False):
            print("\nğŸ¯ PHÃ‚N TÃCH CLASS-SPECIFIC AUGMENTATION:")
            print("=" * 60)
            
            # Khá»Ÿi táº¡o class-specific augmentation
            class_aug = ClassSpecificAugmentation(config)
            
            # Láº¥y class distribution tá»« dataset_info
            class_distribution = dataset_info.get('class_distribution', {})
            if class_distribution:
                # TÃ­nh toÃ¡n káº¿ hoáº¡ch augmentation
                augmentation_plan = class_aug.calculate_augmentation_needs(class_distribution)
                
                # In káº¿ hoáº¡ch augmentation
                class_aug.print_augmentation_plan(class_distribution)
                

                
                # Cáº­p nháº­t aug_stats vá»›i thÃ´ng tin class-specific
                aug_stats['class_specific_info'] = {
                    'augmentation_plan': augmentation_plan,
                    'classes_to_augment': [name for name, plan in augmentation_plan.items() 
                                         if plan['should_augment']],
                    'classes_to_skip': [name for name, plan in augmentation_plan.items() 
                                       if not plan['should_augment']]
                }
                
                # Cáº­p nháº­t config vá»›i thá»‘ng kÃª má»›i (model_info sáº½ Ä‘Æ°á»£c thÃªm sau)
                save_config_to_output_folder(config, config['OUTPUT_FOLDER'], aug_stats)
                
                # Táº¡o Ä‘á»“ thá»‹ so sÃ¡nh augmentation
                print("ğŸ“Š Táº O Äá»’ THá»Š SO SÃNH AUGMENTATION:")
                from analysis.dataset_analysis import create_augmentation_comparison_chart
                aug_comparison_info = create_augmentation_comparison_chart(config['DATASET_PATH'], config, aug_stats)
            else:
                print("âš ï¸ KhÃ´ng thá»ƒ láº¥y thÃ´ng tin class distribution tá»« dataset")
                print("   Dataset info keys:", list(dataset_info.keys()))
        else:
            print("â„¹ï¸ Class-specific augmentation khÃ´ng Ä‘Æ°á»£c báº­t")
            
            # Táº¡o Ä‘á»“ thá»‹ so sÃ¡nh augmentation (cho trÆ°á»ng há»£p khÃ´ng cÃ³ class-specific)
            print("ğŸ“Š Táº O Äá»’ THá»Š SO SÃNH AUGMENTATION:")
            from analysis.dataset_analysis import create_augmentation_comparison_chart
            aug_comparison_info = create_augmentation_comparison_chart(config['DATASET_PATH'], config, aug_stats)
    else:
        # Táº¡o thá»‘ng kÃª giáº£ khi khÃ´ng cÃ³ augmentation
        aug_stats = {
            'total_original_images': dataset_info['total_images'],
            'images_per_episode': config['N_WAY'] * (config['K_SHOT'] + config['Q_QUERY'] + config['Q_VALID']),
            'total_original_used': config['N_WAY'] * (config['K_SHOT'] + config['Q_QUERY'] + config['Q_VALID']) * config['NUM_EPISODES'],
            'augmented_images_per_episode': 0,  # KhÃ´ng cÃ³ augmentation
            'total_augmented_images': 0,  # KhÃ´ng cÃ³ augmentation
            'total_images_after_aug': config['N_WAY'] * (config['K_SHOT'] + config['Q_QUERY'] + config['Q_VALID']) * config['NUM_EPISODES'],
            'augmentation_ratio': 0.0,  # KhÃ´ng cÃ³ augmentation
            'effective_dataset_size': config['N_WAY'] * (config['K_SHOT'] + config['Q_QUERY'] + config['Q_VALID']) * config['NUM_EPISODES']
        }
        
        print("\nğŸ“Š THá»NG KÃŠ (KHÃ”NG CÃ“ AUGMENTATION):")
        print("=" * 50)
        print(f"ğŸ“ˆ Tá»•ng áº£nh gá»‘c trong dataset: {aug_stats['total_original_images']:,}")
        print(f"ğŸ¯ áº¢nh sá»­ dá»¥ng má»—i episode: {aug_stats['images_per_episode']}")
        print(f"ğŸ“¦ Tá»•ng áº£nh Ä‘Æ°á»£c sá»­ dá»¥ng: {aug_stats['total_original_used']:,}")
        print(f"ğŸ”„ áº¢nh Ä‘Æ°á»£c augment: 0 (USE_AUGMENTATION = False)")
        print(f"ğŸ“Š Tá»•ng áº£nh sau augmentation: {aug_stats['total_images_after_aug']:,}")
        print(f"ğŸ“ˆ Tá»· lá»‡ augmentation: 0.00% (USE_AUGMENTATION = False)")
        print(f"ğŸš€ KÃ­ch thÆ°á»›c dataset hiá»‡u quáº£: {aug_stats['effective_dataset_size']:,}")
        print("=" * 50)
        
        # Cáº­p nháº­t config vá»›i thá»‘ng kÃª (model_info sáº½ Ä‘Æ°á»£c thÃªm sau)
        save_config_to_output_folder(config, config['OUTPUT_FOLDER'], aug_stats)
    
    print("\n" + "=" * 60)
    
    # Táº¡o transforms
    transform_basic, transform_augmented, transform_inference = create_transforms(config)
    
    # Khá»Ÿi táº¡o dataset vá»›i data augmentation
    fewshot_data = FewShotDataset(
        config['DATASET_PATH'], 
        transform_train=transform_augmented,
        transform_test=transform_basic
    )
    
    # Khá»Ÿi táº¡o model vá»›i phÆ°Æ¡ng phÃ¡p Ä‘Æ°á»£c chá»n
    distance_method = config.get('DISTANCE_METHOD', 'relation_network')
    use_learnable = config.get('USE_LEARNABLE_METRIC', True)
    transformer_model = config.get('TRANSFORMER_MODEL', 'swin_base_patch4_window7_224')
    
    if use_learnable:
        model = FlexibleDistanceModel(
            embed_dim=config['EMBED_DIM'], 
            relation_dim=config['RELATION_DIM'],
            distance_method=distance_method,
            transformer_model=transformer_model
        ).to(DEVICE)
    else:
        model = FlexibleDistanceModel(
            embed_dim=config['EMBED_DIM'], 
            relation_dim=config['RELATION_DIM'],
            distance_method="euclidean",
            transformer_model=transformer_model
        ).to(DEVICE)
    
    # Táº¡o thÃ´ng tin model Ä‘á»ƒ lÆ°u vÃ o JSON
    transformer_names = {
        'swin_base_patch4_window7_224': 'Swin-Base',
        'swin_large_patch4_window12_384': 'Swin-Large',
        'convnext_base': 'ConvNeXt-Base',
        'convnext_large': 'ConvNeXt-Large'
    }
    
    model_info = {
        'model_name': 'FlexibleDistanceModel',
        'backbone': transformer_names.get(model.transformer_model, model.transformer_model),
        'backbone_architecture': model.transformer_model,
        'embed_dim': config['EMBED_DIM'],
        'relation_dim': config['RELATION_DIM'],
        'distance_method': distance_method,
        'use_learnable_metric': use_learnable,
        'total_parameters': sum(p.numel() for p in model.parameters()),
        'trainable_parameters': sum(p.numel() for p in model.parameters() if p.requires_grad),
        'device': DEVICE
    }
    
    print(f"âœ… Flexible Distance Model Ä‘Ã£ Ä‘Æ°á»£c táº£i lÃªn {DEVICE}")
    print(f"ğŸ“Š Cáº¥u hÃ¬nh: {config['N_WAY']}-way, {config['K_SHOT']}-shot, {config['Q_QUERY']}-query")
    print(f"ğŸ§  Kiáº¿n trÃºc: {model_info['backbone']} + {distance_method.upper()}")
    print(f"ğŸ“ˆ Tá»•ng tham sá»‘: {model_info['total_parameters']:,}")
    print(f"ğŸ”§ Tham sá»‘ cÃ³ thá»ƒ train: {model_info['trainable_parameters']:,}")
    print("=" * 60)
    
    # LÆ°u thÃ´ng tin model vÃ o config JSON
    save_config_to_output_folder(config, config['OUTPUT_FOLDER'], aug_stats, model_info)

    # Cháº¡y episodes vá»›i Relation Network
    use_aug = config.get('USE_AUGMENTATION', False)
    aug_status = "CÃ“ AUGMENTATION" if use_aug else "KHÃ”NG AUGMENTATION"
    
    print(f"\nğŸ¯ CHáº Y {config['NUM_EPISODES']} EPISODES Vá»šI RELATION NETWORK ({aug_status}):")
    results_with_aug = run_multiple_episodes_with_detailed_evaluation(
        model, fewshot_data, config, config['NUM_EPISODES'], 
        use_augmentation=use_aug, include_validation=config['USE_VALIDATION']
    )
    
    print(f"\nğŸ“Š Káº¾T QUáº¢ Vá»šI RELATION NETWORK ({aug_status}):")
    print(f"   Query Accuracy trung bÃ¬nh: {results_with_aug['avg_query_acc']:.4f} Â± {results_with_aug['std_query_acc']:.4f}")
    print(f"   Query Loss trung bÃ¬nh: {results_with_aug['avg_query_loss']:.4f} Â± {results_with_aug['std_query_loss']:.4f}")
    print(f"   Query Accuracy min/max: {results_with_aug['min_query_acc']:.4f} / {results_with_aug['max_query_acc']:.4f}")
    
    if 'avg_valid_acc' in results_with_aug:
        print(f"   Validation Accuracy trung bÃ¬nh: {results_with_aug['avg_valid_acc']:.4f} Â± {results_with_aug['std_valid_acc']:.4f}")
        print(f"   Validation Loss trung bÃ¬nh: {results_with_aug['avg_valid_loss']:.4f} Â± {results_with_aug['std_valid_loss']:.4f}")
        print(f"   Validation Accuracy min/max: {results_with_aug['min_valid_acc']:.4f} / {results_with_aug['max_valid_acc']:.4f}")
        
        # So sÃ¡nh Query vs Validation
        acc_diff = results_with_aug['avg_query_acc'] - results_with_aug['avg_valid_acc']
        print(f"   ChÃªnh lá»‡ch Query-Validation Accuracy: {acc_diff:.4f}")
        if acc_diff > 0.05:
            print(f"   âš ï¸ CÃ³ thá»ƒ bá»‹ overfitting (Query > Validation)")
        elif acc_diff < -0.05:
            print(f"   âš ï¸ CÃ³ thá»ƒ bá»‹ underfitting (Query < Validation)")
        else:
            print(f"   âœ… MÃ´ hÃ¬nh cÃ¢n báº±ng tá»‘t")
    
    # ==== ÄÃNH GIÃ CHI TIáº¾T QUERY SET ====
    print(f"\nğŸ” ÄÃNH GIÃ CHI TIáº¾T QUERY SET:")
    query_predictions = results_with_aug['all_query_predictions']
    query_targets = results_with_aug['all_query_targets']
    
    # Láº¥y tÃªn class thá»±c táº¿ tá»« dataset
    dataset_classes = fewshot_data.dataset.classes
    print(f"ğŸ“‹ CÃ¡c class cÃ³ sáºµn trong dataset: {dataset_classes}")
    print(f"ğŸ¯ Sá»­ dá»¥ng {config['N_WAY']} class trong má»—i episode (chá»n ngáº«u nhiÃªn)")
    
    # Hiá»ƒn thá»‹ cÃ¡c class Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c episodes
    print(f"ğŸ“Š CÃ¡c class Ä‘Æ°á»£c sá»­ dá»¥ng trong {config['NUM_EPISODES']} episodes:")
    for i, episode_classes in enumerate(results_with_aug['all_episode_class_names']):
        print(f"   Episode {i+1}: {episode_classes}")
    
    # Sá»­ dá»¥ng tÃªn class thá»±c táº¿ tá»« episode cuá»‘i cÃ¹ng cho Ä‘Ã¡nh giÃ¡
    class_names = results_with_aug['all_episode_class_names'][-1]  # Láº¥y tÃªn class tá»« episode cuá»‘i
    
    # TÃ­nh metrics chi tiáº¿t
    query_metrics = calculate_detailed_metrics(query_predictions, query_targets, config['N_WAY'])
    
    # In metrics
    print_detailed_evaluation_metrics(query_metrics, class_names, "Query Set")
    
    # Váº½ confusion matrix
    if config['SAVE_RESULTS']:
        plot_confusion_matrix(query_metrics['confusion_matrix'], class_names, "query_confusion_matrix.png", config)
        analyze_accuracy_by_class(query_predictions, query_targets, class_names, "query_accuracy_by_class.png", config)
        # plot_imbalance_analysis(query_metrics, class_names, "query_imbalance_analysis.png", config)
    
    # ==== ÄÃNH GIÃ CHI TIáº¾T VALIDATION SET (náº¿u cÃ³) ====
    if 'all_valid_predictions' in results_with_aug:
        print(f"\nğŸ” ÄÃNH GIÃ CHI TIáº¾T VALIDATION SET:")
        valid_predictions = results_with_aug['all_valid_predictions']
        valid_targets = results_with_aug['all_valid_targets']
        
        # TÃ­nh metrics chi tiáº¿t
        valid_metrics = calculate_detailed_metrics(valid_predictions, valid_targets, config['N_WAY'])
        
        # In metrics (sá»­ dá»¥ng cÃ¹ng tÃªn class thá»±c táº¿)
        print_detailed_evaluation_metrics(valid_metrics, class_names, "Validation Set")
        
        # Váº½ confusion matrix
        if config['SAVE_RESULTS']:
            plot_confusion_matrix(valid_metrics['confusion_matrix'], class_names, "valid_confusion_matrix.png", config)
            analyze_accuracy_by_class(valid_predictions, valid_targets, class_names, "valid_accuracy_by_class.png", config)
            # plot_imbalance_analysis(valid_metrics, class_names, "valid_imbalance_analysis.png", config)
    
    # Váº½ Ä‘á»“ thá»‹ káº¿t quáº£
    if config['SAVE_RESULTS']:
        plot_single_results(results_with_aug, "episode_results_single.png", config)
    
    print("\nâœ… HoÃ n thÃ nh!")
    print(f"ğŸ“ Táº¥t cáº£ káº¿t quáº£ Ä‘Ã£ Ä‘Æ°á»£c lÆ°u trong folder: {config['OUTPUT_FOLDER']}")
    print(f"ğŸ’¾ Cáº¥u hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o: {config['OUTPUT_FOLDER']}/config.json")
    if not config.get('SHOW_PLOTS', False):
        print("ğŸ”‡ Cháº¿ Ä‘á»™ khÃ´ng hiá»ƒn thá»‹ áº£nh pop-up Ä‘Ã£ Ä‘Æ°á»£c báº­t (SHOW_PLOTS = False)")
    print("=" * 60)
    
    print(f"ğŸ“Š Äá»“ thá»‹ phÃ¢n bá»‘ class: {config['OUTPUT_FOLDER']}/class_distribution.png")
    
    if config.get('USE_AUGMENTATION', False):
        print(f"ğŸ“Š Äá»“ thá»‹ so sÃ¡nh augmentation: {config['OUTPUT_FOLDER']}/augmentation_comparison.png")
    
    if config['SAVE_RESULTS']:
            print(f"ğŸ“Š Äá»“ thá»‹ káº¿t quáº£ episodes: {config['OUTPUT_FOLDER']}/episode_results_single.png")
    print(f"ğŸ“Š Confusion matrix: {config['OUTPUT_FOLDER']}/query_confusion_matrix.png")
    print(f"ğŸ“Š Accuracy theo class: {config['OUTPUT_FOLDER']}/query_accuracy_by_class.png")
    

    
    # print(f"ğŸ“Š Imbalance analysis: {config['OUTPUT_FOLDER']}/query_imbalance_analysis.png")
    
    if config['USE_VALIDATION']:
        print(f"ğŸ“Š Validation confusion matrix: {config['OUTPUT_FOLDER']}/valid_confusion_matrix.png")
        print(f"ğŸ“Š Validation accuracy theo class: {config['OUTPUT_FOLDER']}/valid_accuracy_by_class.png")
        # print(f"ğŸ“Š Validation imbalance analysis: {config['OUTPUT_FOLDER']}/valid_imbalance_analysis.png")
    
    print(f"ğŸ§  Model: {model_info['model_name']} ({model_info['backbone']})")
    print(f"ğŸ”§ PhÆ°Æ¡ng phÃ¡p: {distance_method.upper()} ({'CÃ³ thá»ƒ há»c Ä‘Æ°á»£c' if use_learnable else 'Cá»‘ Ä‘á»‹nh'})")
    if use_learnable:
        print(f"ğŸ“ˆ Relation scores: 0-1 (cao hÆ¡n = tÆ°Æ¡ng tá»± hÆ¡n)")
    else:
        print(f"ğŸ“ˆ Euclidean similarity: 0-1 (cao hÆ¡n = tÆ°Æ¡ng tá»± hÆ¡n)")
    print(f"ğŸ”„ Data Augmentation: {'Báº¬T' if config.get('USE_AUGMENTATION', False) else 'Táº®T'} (USE_AUGMENTATION = {config.get('USE_AUGMENTATION', False)})")
    
    print("=" * 60)

if __name__ == "__main__":
    main()
