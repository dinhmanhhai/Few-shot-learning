"""
Module cho balanced dataset - Ä‘áº£m báº£o táº¥t cáº£ class Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ Ä‘á»u Ä‘áº·n
"""
import os
import random
import torch
from torchvision.datasets import ImageFolder
from torchvision import transforms
from PIL import Image
import numpy as np

class BalancedFewShotDataset:
    """
    Dataset cho few-shot learning vá»›i Ä‘Ã¡nh giÃ¡ cÃ¢n báº±ng táº¥t cáº£ class
    """
    def __init__(self, root_dir, transform_train=None, transform_test=None):
        self.root_dir = root_dir
        self.transform_train = transform_train
        self.transform_test = transform_test
        
        # Táº¡o dataset vá»›i transform cÆ¡ báº£n Ä‘á»ƒ láº¥y thÃ´ng tin
        self.dataset = ImageFolder(root_dir, transform=transforms.ToTensor())
        self.class_to_indices = self._group_by_class()
        self.all_classes = list(self.class_to_indices.keys())
        self.num_classes = len(self.all_classes)
        
        print(f"ðŸ“Š Dataset cÃ³ {self.num_classes} class: {self.all_classes}")
        print(f"ðŸ“ˆ Sá»‘ áº£nh má»—i class:")
        for class_id in self.all_classes:
            class_name = self.dataset.classes[class_id]
            num_images = len(self.class_to_indices[class_id])
            print(f"   - {class_name}: {num_images} áº£nh")

    def _group_by_class(self):
        """
        NhÃ³m indices theo class
        """
        class_to_idx = {}
        for idx, (img_path, label) in enumerate(self.dataset.samples):
            class_to_idx.setdefault(label, []).append(idx)
        return class_to_idx

    def load_image_with_transform(self, img_path, use_augmentation=True):
        """
        Load áº£nh vá»›i transform tÆ°Æ¡ng á»©ng
        """
        img = Image.open(img_path).convert('RGB')
        
        # Sá»­ dá»¥ng logic augmentation dá»±a trÃªn tham sá»‘
        if use_augmentation and self.transform_train:
            return self.transform_train(img)
        elif self.transform_test:
            return self.transform_test(img)
        else:
            return transforms.ToTensor()(img)

    def sample_episode_balanced(self, n_way, k_shot, q_query, q_valid=0, use_augmentation=True):
        """
        Sample má»™t episode vá»›i n_way classes, Ä‘áº£m báº£o táº¥t cáº£ class Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»u Ä‘áº·n
        """
        # Chá»n n_way class tá»« táº¥t cáº£ class cÃ³ sáºµn
        if n_way >= self.num_classes:
            # Náº¿u n_way >= sá»‘ class cÃ³ sáºµn, sá»­ dá»¥ng táº¥t cáº£
            selected_classes = self.all_classes.copy()
            print(f"ðŸŽ¯ Sá»­ dá»¥ng táº¥t cáº£ {len(selected_classes)} class: {[self.dataset.classes[c] for c in selected_classes]}")
        else:
            # Náº¿u n_way < sá»‘ class, chá»n ngáº«u nhiÃªn
            selected_classes = random.sample(self.all_classes, n_way)
            print(f"ðŸŽ¯ Chá»n ngáº«u nhiÃªn {n_way} class: {[self.dataset.classes[c] for c in selected_classes]}")
        
        support_idx, query_idx, valid_idx = [], [], []
        label_map = {}
        
        # LÆ°u thÃ´ng tin class Ä‘Æ°á»£c chá»n
        self.selected_class_names = [self.dataset.classes[class_id] for class_id in selected_classes]

        for new_label, class_id in enumerate(selected_classes):
            indices = self.class_to_indices[class_id]
            total_needed = k_shot + q_query + q_valid
            
            # Kiá»ƒm tra xem class cÃ³ Ä‘á»§ áº£nh khÃ´ng
            if len(indices) < total_needed:
                print(f"âš ï¸ Class {self.dataset.classes[class_id]} chá»‰ cÃ³ {len(indices)} áº£nh, cáº§n {total_needed}")
                # Sá»­ dá»¥ng táº¥t cáº£ áº£nh cÃ³ sáºµn
                sampled = indices
                k_actual = min(k_shot, len(indices))
                q_actual = min(q_query, len(indices) - k_actual)
                v_actual = min(q_valid, len(indices) - k_actual - q_actual)
            else:
                sampled = random.sample(indices, total_needed)
                k_actual, q_actual, v_actual = k_shot, q_query, q_valid
            
            support = sampled[:k_actual]
            query = sampled[k_actual:k_actual + q_actual]
            valid = sampled[k_actual + q_actual:k_actual + q_actual + v_actual] if v_actual > 0 else []

            support_idx += support
            query_idx += query
            valid_idx += valid
            label_map[class_id] = new_label

        # Táº¡o support, query vÃ  validation sets
        support_set = []
        query_set = []
        valid_set = []
        
        for i in support_idx:
            img_path, label = self.dataset.samples[i]
            img_tensor = self.load_image_with_transform(img_path, use_augmentation=use_augmentation)
            support_set.append((img_tensor, label_map[label]))
            
        for i in query_idx:
            img_path, label = self.dataset.samples[i]
            img_tensor = self.load_image_with_transform(img_path, use_augmentation=False)
            query_set.append((img_tensor, label_map[label]))
            
        for i in valid_idx:
            img_path, label = self.dataset.samples[i]
            img_tensor = self.load_image_with_transform(img_path, use_augmentation=False)
            valid_set.append((img_tensor, label_map[label]))
            
        return support_set, query_set, valid_set

    def get_class_distribution_stats(self):
        """
        Láº¥y thá»‘ng kÃª phÃ¢n bá»‘ class
        """
        stats = {}
        for class_id in self.all_classes:
            class_name = self.dataset.classes[class_id]
            num_images = len(self.class_to_indices[class_id])
            stats[class_name] = num_images
        return stats

    def get_minimum_episodes_for_all_classes(self, n_way, k_shot, q_query, q_valid=0):
        """
        TÃ­nh sá»‘ episode tá»‘i thiá»ƒu Ä‘á»ƒ má»—i class Ä‘Æ°á»£c sá»­ dá»¥ng Ã­t nháº¥t má»™t láº§n
        """
        images_per_episode = n_way * (k_shot + q_query + q_valid)
        total_images_needed = images_per_episode
        
        # Sá»‘ episode tá»‘i thiá»ƒu Ä‘á»ƒ má»—i class Ä‘Æ°á»£c sá»­ dá»¥ng
        min_episodes = max(1, self.num_classes // n_way)
        
        return min_episodes, total_images_needed
