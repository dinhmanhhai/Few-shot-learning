"""
Main script cho Few-Shot Learning vá»›i cáº¥u trÃºc modular
"""
import torch
import json
import os
from datetime import datetime

# Import cÃ¡c module
from utils.config_loader import load_config, print_config_summary
from utils.transforms import create_transforms
from utils.dataset_finder import DatasetFinder, find_and_display_datasets
from models.backbone import FlexibleDistanceModel
from data.dataset import FewShotDataset
from analysis.dataset_analysis import analyze_and_visualize_dataset
from evaluation.metrics import calculate_detailed_metrics, print_detailed_evaluation_metrics
from visualization.plots import (
    plot_confusion_matrix, 
    analyze_accuracy_by_class, 
    plot_single_results,
    plot_classification_report
)
from training.episode_runner import run_multiple_episodes_with_detailed_evaluation
from utils.class_augmentation import ClassSpecificAugmentation

def save_config_to_output_folder(
    config,
    output_folder,
    aug_stats=None,
    model_info=None,
    results_summary=None,
    query_metrics=None,
    valid_metrics=None,
    plot_paths=None,
    class_metrics=None,
    class_names=None,
    overall_metrics=None,
    detailed_class_metrics=None,
    readable_summary=None,
):
    """
    LÆ°u cáº¥u hÃ¬nh vÃ o file JSON trong folder káº¿t quáº£
    """
    config_file = os.path.join(output_folder, "config.json")
    
    # Táº¡o báº£n sao cá»§a config Ä‘á»ƒ loáº¡i bá» cÃ¡c object khÃ´ng thá»ƒ serialize
    config_to_save = {}
    for key, value in config.items():
        if isinstance(value, (str, int, float, bool, list, dict)):
            config_to_save[key] = value
        else:
            config_to_save[key] = str(value)  # Chuyá»ƒn thÃ nh string náº¿u khÃ´ng thá»ƒ serialize
    
    # ThÃªm timestamp
    config_to_save['timestamp'] = datetime.now().isoformat()
    config_to_save['output_folder'] = output_folder
    
    # ThÃªm thÃ´ng tin model náº¿u cÃ³
    if model_info:
        config_to_save['model_info'] = model_info
    
    # ThÃªm thá»‘ng kÃª augmentation náº¿u cÃ³
    if aug_stats:
        config_to_save['augmentation_stats'] = aug_stats
    
    # ThÃªm tÃ³m táº¯t káº¿t quáº£ náº¿u cÃ³
    if results_summary:
        config_to_save['results_summary'] = results_summary
    
    # Bá» lÆ°u metrics chi tiáº¿t (arrays) vÃ¬ khÃ³ Ä‘á»c
    # Chá»‰ giá»¯ láº¡i cáº¥u trÃºc dá»… Ä‘á»c vá»›i tÃªn class
    
    # ThÃªm Ä‘Æ°á»ng dáº«n file káº¿t quáº£ náº¿u cÃ³
    if plot_paths:
        config_to_save['artifacts'] = plot_paths
    
    # Bá» lÆ°u per_class_metrics cÅ© (array format) vÃ¬ khÃ³ Ä‘á»c
    # Chá»‰ giá»¯ láº¡i detailed_class_metrics vÃ  readable_summary
    
    # Bá» lÆ°u detailed_class_metrics vÃ¬ khÃ¡ dÃ i dÃ²ng
    # Chá»‰ giá»¯ láº¡i readable_summary vÃ  overall_metrics
    
    # ThÃªm summary dá»… Ä‘á»c
    if readable_summary:
        config_to_save['readable_summary'] = readable_summary
    
    # ThÃªm metrics tá»•ng quan (macro/weighted) náº¿u cÃ³
    if overall_metrics:
        config_to_save['overall_metrics'] = overall_metrics
    
    # LÆ°u danh sÃ¡ch tÃªn class náº¿u cÃ³
    if class_names:
        config_to_save['class_names'] = class_names
    
    with open(config_file, 'w', encoding='utf-8') as f:
        json.dump(config_to_save, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ’¾ Cáº¥u hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o: {config_file}")

def calculate_augmentation_stats(config, dataset_info):
    """
    TÃ­nh toÃ¡n thá»‘ng kÃª vá» data augmentation
    """
    total_original_images = dataset_info['total_images']
    n_way = config['N_WAY']
    k_shot = config['K_SHOT']
    q_query = config['Q_QUERY']
    q_valid = config['Q_VALID'] if config['USE_VALIDATION'] else 0
    num_episodes = config['NUM_EPISODES']
    
    # Sá»‘ áº£nh gá»‘c Ä‘Æ°á»£c sá»­ dá»¥ng trong má»—i episode
    images_per_episode = n_way * (k_shot + q_query + q_valid)
    
    # Tá»•ng sá»‘ áº£nh gá»‘c Ä‘Æ°á»£c sá»­ dá»¥ng
    total_original_used = images_per_episode * num_episodes
    
    # TÃ­nh toÃ¡n hiá»‡u quáº£ augmentation
    # Má»—i áº£nh support (k_shot) sáº½ Ä‘Æ°á»£c augment
    augmented_images_per_episode = n_way * k_shot
    total_augmented_images = augmented_images_per_episode * num_episodes
    
    # Tá»•ng sá»‘ áº£nh sau augmentation (gá»‘c + augmented)
    total_images_after_aug = total_original_used + total_augmented_images
    
    # Tá»· lá»‡ augmentation
    augmentation_ratio = total_augmented_images / total_original_used if total_original_used > 0 else 0
    
    stats = {
        'total_original_images': total_original_images,
        'images_per_episode': images_per_episode,
        'total_original_used': total_original_used,
        'augmented_images_per_episode': augmented_images_per_episode,
        'total_augmented_images': total_augmented_images,
        'total_images_after_aug': total_images_after_aug,
        'augmentation_ratio': augmentation_ratio,
        'effective_dataset_size': total_images_after_aug
    }
    
    return stats

def print_augmentation_stats(aug_stats, config):
    """
    In thá»‘ng kÃª augmentation
    """
    print("\nğŸ“Š THá»NG KÃŠ DATA AUGMENTATION:")
    print("=" * 50)
    print(f"ğŸ“ˆ Tá»•ng áº£nh gá»‘c trong dataset: {aug_stats['total_original_images']:,}")
    print(f"ğŸ¯ áº¢nh sá»­ dá»¥ng má»—i episode: {aug_stats['images_per_episode']}")
    # print(f"ğŸ“¦ Tá»•ng áº£nh gá»‘c Ä‘Æ°á»£c sá»­ dá»¥ng: {aug_stats['total_original_used']:,}")
    # print(f"ğŸ”„ áº¢nh Ä‘Æ°á»£c augment má»—i episode: {aug_stats['augmented_images_per_episode']}")
    # print(f"âœ¨ Tá»•ng áº£nh Ä‘Æ°á»£c augment: {aug_stats['total_augmented_images']:,}")
    # print(f"ğŸ“Š Tá»•ng áº£nh sau augmentation: {aug_stats['total_images_after_aug']:,}")
    # print(f"ğŸ“ˆ Tá»· lá»‡ augmentation: {aug_stats['augmentation_ratio']:.2%}")
    # print(f"ğŸš€ KÃ­ch thÆ°á»›c dataset hiá»‡u quáº£: {aug_stats['effective_dataset_size']:,}")
    
    # TÃ­nh toÃ¡n tá»•ng sá»‘ lÆ°á»£ng áº£nh cá»§a dataset sau augmentation
    total_dataset_after_aug = aug_stats['total_original_images'] + aug_stats['total_augmented_images']
    print(f"ğŸ“Š Tá»•ng sá»‘ lÆ°á»£ng áº£nh dataset sau augmentation: {total_dataset_after_aug:,}")
    print(f"ğŸ“ˆ Tá»· lá»‡ tÄƒng dataset: {(aug_stats['total_augmented_images']/aug_stats['total_original_images'])*100:.1f}%")
    
    # ThÃ´ng tin vá» config Ä‘Æ°á»£c sá»­ dá»¥ng
    print(f"\nâš™ï¸ Cáº¤U HÃŒNH FEW-SHOT LEARNING:")
    print(f"   â€¢ {config['N_WAY']}-way, {config['K_SHOT']}-shot, {config['Q_QUERY']}-query, {config['Q_VALID']}-valid")
    print(f"   â€¢ Sá»‘ episodes: {config['NUM_EPISODES']}")
    print(f"   â€¢ Tá»•ng áº£nh Ä‘Æ°á»£c sá»­ dá»¥ng: {aug_stats['total_original_used']:,} (gá»‘c) + {aug_stats['total_augmented_images']:,} (augment) = {aug_stats['total_images_after_aug']:,}")
    print(f"   â€¢ Tá»· lá»‡ sá»­ dá»¥ng dataset: {(aug_stats['total_images_after_aug']/total_dataset_after_aug)*100:.1f}%")
    
    # ThÃ´ng tin chi tiáº¿t vá» augmentation
    aug_config = config['AUGMENTATION_CONFIG']
    print(f"\nğŸ”§ Cáº¥u hÃ¬nh augmentation:")
    print(f"   - Random Crop: +{aug_config['random_crop_size']}px")
    print(f"   - Rotation: Â±{aug_config['rotation_degrees']}Â°")
    print(f"   - Horizontal Flip: {aug_config['flip_probability']:.1%}")
    print(f"   - Color Jitter: Brightness={aug_config['color_jitter']['brightness']}, "
          f"Contrast={aug_config['color_jitter']['contrast']}, "
          f"Saturation={aug_config['color_jitter']['saturation']}, "
          f"Hue={aug_config['color_jitter']['hue']}")
    print(f"   - Grayscale: {aug_config['grayscale_probability']:.1%}")
    
    print("=" * 50)

def find_and_select_dataset(config):
    """
    TÃ¬m vÃ  chá»n dataset tá»± Ä‘á»™ng
    
    Args:
        config: Cáº¥u hÃ¬nh há»‡ thá»‘ng
        
    Returns:
        ÄÆ°á»ng dáº«n dataset Ä‘Æ°á»£c chá»n
    """
    # Láº¥y Ä‘Æ°á»ng dáº«n chÃ­nh tá»« config
    main_dataset_path = config.get('DATASET_PATH', r'D:\AI\New-Dataset')
    return main_dataset_path

def main():
    """
    Main function
    """
    print("ğŸš€ Khá»Ÿi táº¡o Few-Shot Learning vá»›i Data Augmentation")
    print("=" * 60)
    
    # Load cáº¥u hÃ¬nh
    config = load_config()
    print_config_summary(config)
    
    # TÃ¬m vÃ  chá»n dataset
    selected_dataset_path = find_and_select_dataset(config)
    config['DATASET_PATH'] = selected_dataset_path
    print(f"\nğŸ“ Dataset Ä‘Æ°á»£c chá»n: {selected_dataset_path}")
    print("=" * 60)
    
    # PhÃ¢n tÃ­ch dataset Ä‘á»ƒ láº¥y sá»‘ class thá»±c táº¿
    print("ğŸ” PhÃ¢n tÃ­ch dataset Ä‘á»ƒ Ä‘iá»u chá»‰nh cáº¥u hÃ¬nh...")
    from analysis.dataset_analysis import analyze_and_visualize_dataset
    dataset_info = analyze_and_visualize_dataset(selected_dataset_path, config)
    
    if dataset_info:
        actual_num_classes = len(dataset_info['class_names'])
        config_n_way = config.get('N_WAY', 6)
        
        if actual_num_classes < config_n_way:
            print(f"âš ï¸ Dataset chá»‰ cÃ³ {actual_num_classes} class, Ä‘iá»u chá»‰nh N_WAY tá»« {config_n_way} xuá»‘ng {actual_num_classes}")
            config['N_WAY'] = actual_num_classes
        elif actual_num_classes > config_n_way:
            print(f"â„¹ï¸ Dataset cÃ³ {actual_num_classes} class, cÃ³ thá»ƒ tÄƒng N_WAY lÃªn {actual_num_classes} náº¿u muá»‘n")
            print(f"   Hiá»‡n táº¡i sá»­ dá»¥ng N_WAY = {config_n_way}")
        
        print(f"âœ… Cáº¥u hÃ¬nh cuá»‘i cÃ¹ng: {config['N_WAY']}-way, {config['K_SHOT']}-shot, {config['Q_QUERY']}-query")
    else:
        print("âš ï¸ KhÃ´ng thá»ƒ phÃ¢n tÃ­ch dataset, sá»­ dá»¥ng cáº¥u hÃ¬nh máº·c Ä‘á»‹nh")
    
    print("=" * 60)
    
    # LÆ°u cáº¥u hÃ¬nh vÃ o folder káº¿t quáº£ (sáº½ cáº­p nháº­t sau khi cÃ³ model_info vÃ  aug_stats)
    save_config_to_output_folder(config, config['OUTPUT_FOLDER'])
    
    # Thiáº¿t láº­p device
    DEVICE = 'cuda' if torch.cuda.is_available() and config['USE_CUDA'] else 'cpu'
    config['DEVICE'] = DEVICE
    
    # PhÃ¢n tÃ­ch dataset (Ä‘Ã£ thá»±c hiá»‡n á»Ÿ trÃªn)
    print("ğŸ“ˆ PHÃ‚N TÃCH DATASET:")
    # dataset_info Ä‘Ã£ Ä‘Æ°á»£c láº¥y á»Ÿ trÃªn
    
    # Táº¡o Ä‘á»“ thá»‹ phÃ¢n bá»‘ class riÃªng biá»‡t
    print("ğŸ“Š Táº O Äá»’ THá»Š PHÃ‚N Bá» CLASS:")
    from analysis.dataset_analysis import create_class_distribution_chart
    class_dist_info = create_class_distribution_chart(config['DATASET_PATH'], config)
    
    if dataset_info is None:
        print("âŒ KhÃ´ng thá»ƒ phÃ¢n tÃ­ch dataset. ThoÃ¡t chÆ°Æ¡ng trÃ¬nh.")
        exit()
    
    # Debug: Kiá»ƒm tra class distribution
    print(f"ğŸ” Debug - Dataset info keys: {list(dataset_info.keys())}")
    if 'class_distribution' in dataset_info:
        print(f"ğŸ“Š Class distribution cÃ³ sáºµn: {len(dataset_info['class_distribution'])} classes")
    else:
        print("âš ï¸ KhÃ´ng cÃ³ class_distribution trong dataset_info")
    
    # Kiá»ƒm tra xem dataset cÃ³ Ä‘á»§ dá»¯ liá»‡u cho few-shot learning khÃ´ng
    if dataset_info['total_images'] < config['N_WAY'] * (config['K_SHOT'] + config['Q_QUERY']):
        print(f"âš ï¸ Cáº£nh bÃ¡o: Dataset cÃ³ thá»ƒ khÃ´ng Ä‘á»§ dá»¯ liá»‡u cho {config['N_WAY']}-way {config['K_SHOT']}-shot learning")
        print(f"   Cáº§n Ã­t nháº¥t {config['N_WAY'] * (config['K_SHOT'] + config['Q_QUERY'])} áº£nh, hiá»‡n cÃ³ {dataset_info['total_images']} áº£nh")
    
    # TÃ­nh toÃ¡n vÃ  hiá»ƒn thá»‹ thá»‘ng kÃª augmentation
    if config.get('USE_AUGMENTATION', False):
        aug_stats = calculate_augmentation_stats(config, dataset_info)
        print_augmentation_stats(aug_stats, config)
        
        # Cáº­p nháº­t config vá»›i thá»‘ng kÃª augmentation (model_info sáº½ Ä‘Æ°á»£c thÃªm sau)
        save_config_to_output_folder(config, config['OUTPUT_FOLDER'], aug_stats)
        
        # Xá»­ lÃ½ class-specific augmentation
        if config.get('CLASS_AUGMENTATION', {}).get('enable_selective', False):
            print("\nğŸ¯ PHÃ‚N TÃCH CLASS-SPECIFIC AUGMENTATION:")
            print("=" * 60)
            
            # Khá»Ÿi táº¡o class-specific augmentation
            class_aug = ClassSpecificAugmentation(config)
            
            # Láº¥y class distribution tá»« dataset_info
            class_distribution = dataset_info.get('class_distribution', {})
            if class_distribution:
                # TÃ­nh toÃ¡n káº¿ hoáº¡ch augmentation
                augmentation_plan = class_aug.calculate_augmentation_needs(class_distribution)
                
                # In káº¿ hoáº¡ch augmentation
                class_aug.print_augmentation_plan(class_distribution)
                

                
                # Cáº­p nháº­t aug_stats vá»›i thÃ´ng tin class-specific
                aug_stats['class_specific_info'] = {
                    'augmentation_plan': augmentation_plan,
                    'classes_to_augment': [name for name, plan in augmentation_plan.items() 
                                         if plan['should_augment']],
                    'classes_to_skip': [name for name, plan in augmentation_plan.items() 
                                       if not plan['should_augment']]
                }
                
                # Cáº­p nháº­t config vá»›i thá»‘ng kÃª má»›i (model_info sáº½ Ä‘Æ°á»£c thÃªm sau)
                save_config_to_output_folder(config, config['OUTPUT_FOLDER'], aug_stats)
                
                # Táº¡o Ä‘á»“ thá»‹ so sÃ¡nh augmentation
                print("ğŸ“Š Táº O Äá»’ THá»Š SO SÃNH AUGMENTATION:")
                from analysis.dataset_analysis import create_augmentation_comparison_chart
                aug_comparison_info = create_augmentation_comparison_chart(config['DATASET_PATH'], config, aug_stats)
            else:
                print("âš ï¸ KhÃ´ng thá»ƒ láº¥y thÃ´ng tin class distribution tá»« dataset")
                print("   Dataset info keys:", list(dataset_info.keys()))
        else:
            print("â„¹ï¸ Class-specific augmentation khÃ´ng Ä‘Æ°á»£c báº­t")
            
            # Táº¡o Ä‘á»“ thá»‹ so sÃ¡nh augmentation (cho trÆ°á»ng há»£p khÃ´ng cÃ³ class-specific)
            print("ğŸ“Š Táº O Äá»’ THá»Š SO SÃNH AUGMENTATION:")
            from analysis.dataset_analysis import create_augmentation_comparison_chart
            aug_comparison_info = create_augmentation_comparison_chart(config['DATASET_PATH'], config, aug_stats)
    else:
        # Táº¡o thá»‘ng kÃª giáº£ khi khÃ´ng cÃ³ augmentation
        aug_stats = {
            'total_original_images': dataset_info['total_images'],
            'images_per_episode': config['N_WAY'] * (config['K_SHOT'] + config['Q_QUERY'] + config['Q_VALID']),
            'total_original_used': config['N_WAY'] * (config['K_SHOT'] + config['Q_QUERY'] + config['Q_VALID']) * config['NUM_EPISODES'],
            'augmented_images_per_episode': 0,  # KhÃ´ng cÃ³ augmentation
            'total_augmented_images': 0,  # KhÃ´ng cÃ³ augmentation
            'total_images_after_aug': config['N_WAY'] * (config['K_SHOT'] + config['Q_QUERY'] + config['Q_VALID']) * config['NUM_EPISODES'],
            'augmentation_ratio': 0.0,  # KhÃ´ng cÃ³ augmentation
            'effective_dataset_size': config['N_WAY'] * (config['K_SHOT'] + config['Q_QUERY'] + config['Q_VALID']) * config['NUM_EPISODES']
        }
        
        print("\nğŸ“Š THá»NG KÃŠ (KHÃ”NG CÃ“ AUGMENTATION):")
        print("=" * 50)
        print(f"ğŸ“ˆ Tá»•ng áº£nh gá»‘c trong dataset: {aug_stats['total_original_images']:,}")
        print(f"ğŸ¯ áº¢nh sá»­ dá»¥ng má»—i episode: {aug_stats['images_per_episode']}")
        print(f"ğŸ“¦ Tá»•ng áº£nh Ä‘Æ°á»£c sá»­ dá»¥ng: {aug_stats['total_original_used']:,}")
        print(f"ğŸ”„ áº¢nh Ä‘Æ°á»£c augment: 0 (USE_AUGMENTATION = False)")
        print(f"ğŸ“Š Tá»•ng áº£nh sau augmentation: {aug_stats['total_images_after_aug']:,}")
        print(f"ğŸ“ˆ Tá»· lá»‡ augmentation: 0.00% (USE_AUGMENTATION = False)")
        print(f"ğŸš€ KÃ­ch thÆ°á»›c dataset hiá»‡u quáº£: {aug_stats['effective_dataset_size']:,}")
        print("=" * 50)
        
        # Cáº­p nháº­t config vá»›i thá»‘ng kÃª (model_info sáº½ Ä‘Æ°á»£c thÃªm sau)
        save_config_to_output_folder(config, config['OUTPUT_FOLDER'], aug_stats)
    
    print("\n" + "=" * 60)
    
    # Táº¡o transforms
    transform_basic, transform_augmented, transform_inference = create_transforms(config)
    
    # Khá»Ÿi táº¡o dataset vá»›i data augmentation
    fewshot_data = FewShotDataset(
        config['DATASET_PATH'], 
        transform_train=transform_augmented,
        transform_test=transform_basic
    )
    
    # Khá»Ÿi táº¡o model vá»›i phÆ°Æ¡ng phÃ¡p Ä‘Æ°á»£c chá»n
    distance_method = config.get('DISTANCE_METHOD', 'relation_network')
    use_learnable = config.get('USE_LEARNABLE_METRIC', True)
    transformer_model = config.get('TRANSFORMER_MODEL', 'swin_base_patch4_window7_224')
    
    # Láº¥y pre-trained model cho Relation Network tá»« config
    relation_pretrained_model = config.get('RELATION_PRETRAINED_MODEL', 'mobilenet_v2')
    
    if use_learnable:
        model = FlexibleDistanceModel(
            embed_dim=config['EMBED_DIM'], 
            relation_dim=config['RELATION_DIM'],
            distance_method=distance_method,
            transformer_model=transformer_model,
            relation_pretrained_model=relation_pretrained_model
        ).to(DEVICE)
    else:
        model = FlexibleDistanceModel(
            embed_dim=config['EMBED_DIM'], 
            relation_dim=config['RELATION_DIM'],
            distance_method="euclidean",
            transformer_model=transformer_model,
            relation_pretrained_model=relation_pretrained_model
        ).to(DEVICE)
    
    # Táº¡o thÃ´ng tin model Ä‘á»ƒ lÆ°u vÃ o JSON
    transformer_names = {
        'swin_base_patch4_window7_224': 'Swin-Base',
        'swin_large_patch4_window12_384': 'Swin-Large',
        'convnext_base': 'ConvNeXt-Base',
        'convnext_large': 'ConvNeXt-Large'
    }
    
    model_info = {
        'model_name': 'FlexibleDistanceModel',
        'backbone': transformer_names.get(model.transformer_model, model.transformer_model),
        'backbone_architecture': model.transformer_model,
        'embed_dim': config['EMBED_DIM'],
        'relation_dim': config['RELATION_DIM'],
        'distance_method': distance_method,
        'use_learnable_metric': use_learnable,
        'relation_pretrained_model': relation_pretrained_model,
        'total_parameters': sum(p.numel() for p in model.parameters()),
        'trainable_parameters': sum(p.numel() for p in model.parameters() if p.requires_grad),
        'device': DEVICE
    }
    
    print(f"âœ… Flexible Distance Model Ä‘Ã£ Ä‘Æ°á»£c táº£i lÃªn {DEVICE}")
    print(f"ğŸ“Š Cáº¥u hÃ¬nh: {config['N_WAY']}-way, {config['K_SHOT']}-shot, {config['Q_QUERY']}-query")
    print(f"ğŸ§  Kiáº¿n trÃºc: {model_info['backbone']} + {distance_method.upper()}")
    print(f"ğŸ“ˆ Tá»•ng tham sá»‘: {model_info['total_parameters']:,}")
    print(f"ğŸ”§ Tham sá»‘ cÃ³ thá»ƒ train: {model_info['trainable_parameters']:,}")
    print("=" * 60)
    
    # LÆ°u thÃ´ng tin model vÃ o config JSON
    save_config_to_output_folder(config, config['OUTPUT_FOLDER'], aug_stats, model_info)

    # Cháº¡y episodes vá»›i Relation Network
    use_aug = config.get('USE_AUGMENTATION', False)
    aug_status = "CÃ“ AUGMENTATION" if use_aug else "KHÃ”NG AUGMENTATION"
    
    print(f"\nğŸ¯ CHáº Y {config['NUM_EPISODES']} EPISODES Vá»šI RELATION NETWORK ({aug_status}):")
    results_with_aug = run_multiple_episodes_with_detailed_evaluation(
        model, fewshot_data, config, config['NUM_EPISODES'], 
        use_augmentation=use_aug, include_validation=config['USE_VALIDATION']
    )
    
    print(f"\nğŸ“Š Káº¾T QUáº¢ Vá»šI RELATION NETWORK ({aug_status}):")
    print(f"   Query Accuracy trung bÃ¬nh: {results_with_aug['avg_query_acc']:.4f} Â± {results_with_aug['std_query_acc']:.4f}")
    print(f"   Query Loss trung bÃ¬nh: {results_with_aug['avg_query_loss']:.4f} Â± {results_with_aug['std_query_loss']:.4f}")
    print(f"   Query Accuracy min/max: {results_with_aug['min_query_acc']:.4f} / {results_with_aug['max_query_acc']:.4f}")
    
    if 'avg_valid_acc' in results_with_aug:
        print(f"   Validation Accuracy trung bÃ¬nh: {results_with_aug['avg_valid_acc']:.4f} Â± {results_with_aug['std_valid_acc']:.4f}")
        print(f"   Validation Loss trung bÃ¬nh: {results_with_aug['avg_valid_loss']:.4f} Â± {results_with_aug['std_valid_loss']:.4f}")
        print(f"   Validation Accuracy min/max: {results_with_aug['min_valid_acc']:.4f} / {results_with_aug['max_valid_acc']:.4f}")
        
        # So sÃ¡nh Query vs Validation
        acc_diff = results_with_aug['avg_query_acc'] - results_with_aug['avg_valid_acc']
        print(f"   ChÃªnh lá»‡ch Query-Validation Accuracy: {acc_diff:.4f}")
        if acc_diff > 0.05:
            print(f"   âš ï¸ CÃ³ thá»ƒ bá»‹ overfitting (Query > Validation)")
        elif acc_diff < -0.05:
            print(f"   âš ï¸ CÃ³ thá»ƒ bá»‹ underfitting (Query < Validation)")
        else:
            print(f"   âœ… MÃ´ hÃ¬nh cÃ¢n báº±ng tá»‘t")
    
    # ==== ÄÃNH GIÃ CHI TIáº¾T QUERY SET ====
    print(f"\nğŸ” ÄÃNH GIÃ CHI TIáº¾T QUERY SET:")
    query_predictions = results_with_aug['all_query_predictions']
    query_targets = results_with_aug['all_query_targets']
    
    # Láº¥y tÃªn class thá»±c táº¿ tá»« dataset
    dataset_classes = fewshot_data.dataset.classes
    print(f"ğŸ“‹ CÃ¡c class cÃ³ sáºµn trong dataset: {dataset_classes}")
    print(f"ğŸ¯ Sá»­ dá»¥ng {config['N_WAY']} class trong má»—i episode (chá»n ngáº«u nhiÃªn)")
    
    # Hiá»ƒn thá»‹ cÃ¡c class Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c episodes
    print(f"ğŸ“Š CÃ¡c class Ä‘Æ°á»£c sá»­ dá»¥ng trong {config['NUM_EPISODES']} episodes:")
    for i, episode_classes in enumerate(results_with_aug['all_episode_class_names']):
        print(f"   Episode {i+1}: {episode_classes}")
    
    # Sá»­ dá»¥ng tÃªn class thá»±c táº¿ tá»« episode cuá»‘i cÃ¹ng cho Ä‘Ã¡nh giÃ¡
    class_names = results_with_aug['all_episode_class_names'][-1]  # Láº¥y tÃªn class tá»« episode cuá»‘i
    
    # TÃ­nh metrics chi tiáº¿t
    query_metrics = calculate_detailed_metrics(query_predictions, query_targets, config['N_WAY'])
    
    # In metrics
    print_detailed_evaluation_metrics(query_metrics, class_names, "Query Set")
    
    # Váº½ confusion matrix
    if config['SAVE_RESULTS']:
        plot_confusion_matrix(query_metrics['confusion_matrix'], class_names, "query_confusion_matrix.png", config)
        analyze_accuracy_by_class(query_predictions, query_targets, class_names, "query_accuracy_by_class.png", config)
        plot_classification_report(query_metrics, class_names, "query_classification_report.png", config, "Query Set")
        # plot_imbalance_analysis(query_metrics, class_names, "query_imbalance_analysis.png", config)
    
    # ==== ÄÃNH GIÃ CHI TIáº¾T VALIDATION SET (náº¿u cÃ³) ====
    if 'all_valid_predictions' in results_with_aug:
        print(f"\nğŸ” ÄÃNH GIÃ CHI TIáº¾T VALIDATION SET:")
        valid_predictions = results_with_aug['all_valid_predictions']
        valid_targets = results_with_aug['all_valid_targets']
        
        # TÃ­nh metrics chi tiáº¿t
        valid_metrics = calculate_detailed_metrics(valid_predictions, valid_targets, config['N_WAY'])
        
        # In metrics (sá»­ dá»¥ng cÃ¹ng tÃªn class thá»±c táº¿)
        print_detailed_evaluation_metrics(valid_metrics, class_names, "Validation Set")
        
        # Váº½ confusion matrix
        if config['SAVE_RESULTS']:
            plot_confusion_matrix(valid_metrics['confusion_matrix'], class_names, "valid_confusion_matrix.png", config)
            analyze_accuracy_by_class(valid_predictions, valid_targets, class_names, "valid_accuracy_by_class.png", config)
            plot_classification_report(valid_metrics, class_names, "valid_classification_report.png", config, "Validation Set")
            # plot_imbalance_analysis(valid_metrics, class_names, "valid_imbalance_analysis.png", config)
    
    # Váº½ Ä‘á»“ thá»‹ káº¿t quáº£
    if config['SAVE_RESULTS']:
        plot_single_results(results_with_aug, "episode_results_single.png", config)
    
    # Chuáº©n bá»‹ tá»•ng há»£p káº¿t quáº£ Ä‘á»ƒ lÆ°u JSON
    results_summary = {
        'avg_query_acc': results_with_aug['avg_query_acc'],
        'std_query_acc': results_with_aug['std_query_acc'],
        'min_query_acc': results_with_aug['min_query_acc'],
        'max_query_acc': results_with_aug['max_query_acc'],
        'avg_query_loss': results_with_aug['avg_query_loss'],
        'std_query_loss': results_with_aug['std_query_loss'],
    }
    if 'avg_valid_acc' in results_with_aug:
        results_summary.update({
            'avg_valid_acc': results_with_aug['avg_valid_acc'],
            'std_valid_acc': results_with_aug['std_valid_acc'],
            'min_valid_acc': results_with_aug['min_valid_acc'],
            'max_valid_acc': results_with_aug['max_valid_acc'],
            'avg_valid_loss': results_with_aug['avg_valid_loss'],
            'std_valid_loss': results_with_aug['std_valid_loss'],
        })
    
    # Táº¡o metrics theo tá»«ng class (gáº¯n tÃªn class) cho Query vÃ  Validation (náº¿u cÃ³)
    def _build_class_metrics(metrics_obj, names):
        class_metrics = {}
        for i, class_name in enumerate(names):
            class_metrics[class_name] = {
                'precision': float(metrics_obj['precision_per_class'][i]),
                'recall': float(metrics_obj['recall_per_class'][i]),
                'f1_score': float(metrics_obj['f1_per_class'][i]),
                'support': int(metrics_obj['support_per_class'][i]),
            }
        return class_metrics
    
    def _build_overall_metrics(metrics_obj):
        return {
            'macro_precision': float(metrics_obj['macro_precision']),
            'macro_recall': float(metrics_obj['macro_recall']),
            'macro_f1': float(metrics_obj['macro_f1']),
            'weighted_precision': float(metrics_obj['weighted_precision']),
            'weighted_recall': float(metrics_obj['weighted_recall']),
            'weighted_f1': float(metrics_obj['weighted_f1']),
        }
    
    # Táº¡o cáº¥u trÃºc metrics rÃµ rÃ ng theo tÃªn class
    detailed_class_metrics = {
        'query': _build_class_metrics(query_metrics, class_names)
    }
    overall_metrics = {
        'query': _build_overall_metrics(query_metrics)
    }
    
    if 'all_valid_predictions' in results_with_aug:
        detailed_class_metrics['valid'] = _build_class_metrics(valid_metrics, class_names)
        overall_metrics['valid'] = _build_overall_metrics(valid_metrics)
    
    # Táº¡o summary table dá»… Ä‘á»c
    def _create_readable_summary(metrics_dict, dataset_name):
        summary = {
            'dataset': dataset_name,
            'class_performance': {}
        }
        
        for class_name, metrics in metrics_dict.items():
            summary['class_performance'][class_name] = {
                'precision': f"{metrics['precision']:.4f}",
                'recall': f"{metrics['recall']:.4f}",
                'f1_score': f"{metrics['f1_score']:.4f}",
                'support': metrics['support']
            }
        
        return summary
    
    # Táº¡o summary dá»… Ä‘á»c
    readable_summary = {
        'query': _create_readable_summary(detailed_class_metrics['query'], 'Query Set')
    }
    if 'valid' in detailed_class_metrics:
        readable_summary['valid'] = _create_readable_summary(detailed_class_metrics['valid'], 'Validation Set')
    
    # ÄÆ°á»ng dáº«n artifact Ä‘Ã£ lÆ°u
    artifacts = {
        'class_distribution': os.path.join(config['OUTPUT_FOLDER'], 'class_distribution.png'),
        'episode_results_single': os.path.join(config['OUTPUT_FOLDER'], 'episode_results_single.png') if config['SAVE_RESULTS'] else None,
        'query_confusion_matrix': os.path.join(config['OUTPUT_FOLDER'], 'query_confusion_matrix.png') if config['SAVE_RESULTS'] else None,
        'query_accuracy_by_class': os.path.join(config['OUTPUT_FOLDER'], 'query_accuracy_by_class.png') if config['SAVE_RESULTS'] else None,
        'query_classification_report': os.path.join(config['OUTPUT_FOLDER'], 'query_classification_report.png') if config['SAVE_RESULTS'] else None,
        'valid_confusion_matrix': os.path.join(config['OUTPUT_FOLDER'], 'valid_confusion_matrix.png') if config['SAVE_RESULTS'] and config['USE_VALIDATION'] else None,
        'valid_accuracy_by_class': os.path.join(config['OUTPUT_FOLDER'], 'valid_accuracy_by_class.png') if config['SAVE_RESULTS'] and config['USE_VALIDATION'] else None,
        'valid_classification_report': os.path.join(config['OUTPUT_FOLDER'], 'valid_classification_report.png') if config['SAVE_RESULTS'] and config['USE_VALIDATION'] else None,
        'augmentation_comparison': os.path.join(config['OUTPUT_FOLDER'], 'augmentation_comparison.png') if config.get('USE_AUGMENTATION', False) else None,
    }
    
    # LÆ°u cáº­p nháº­t cuá»‘i vÃ o JSON (gá»“m results, metrics, artifacts)
    save_config_to_output_folder(
        config,
        config['OUTPUT_FOLDER'],
        aug_stats,
        model_info,
        results_summary=results_summary,
        query_metrics=None,  # Bá» lÆ°u vÃ¬ khÃ³ Ä‘á»c
        valid_metrics=None,  # Bá» lÆ°u vÃ¬ khÃ³ Ä‘á»c
        plot_paths=artifacts,
        class_metrics=None,  # Bá» lÆ°u vÃ¬ khÃ³ Ä‘á»c
        class_names=class_names,
        overall_metrics=overall_metrics,
        detailed_class_metrics=None,  # Bá» lÆ°u vÃ¬ dÃ i dÃ²ng
        readable_summary=readable_summary,
    )

    print("\nâœ… HoÃ n thÃ nh!")
    print(f"ğŸ“ Táº¥t cáº£ káº¿t quáº£ Ä‘Ã£ Ä‘Æ°á»£c lÆ°u trong folder: {config['OUTPUT_FOLDER']}")
    print(f"ğŸ’¾ Cáº¥u hÃ¬nh vÃ  káº¿t quáº£ Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o: {config['OUTPUT_FOLDER']}/config.json")
    if not config.get('SHOW_PLOTS', False):
        print("ğŸ”‡ Cháº¿ Ä‘á»™ khÃ´ng hiá»ƒn thá»‹ áº£nh pop-up Ä‘Ã£ Ä‘Æ°á»£c báº­t (SHOW_PLOTS = False)")
    print("=" * 60)
    
    print(f"ğŸ“Š Äá»“ thá»‹ phÃ¢n bá»‘ class: {config['OUTPUT_FOLDER']}/class_distribution.png")
    
    if config.get('USE_AUGMENTATION', False):
        print(f"ğŸ“Š Äá»“ thá»‹ so sÃ¡nh augmentation: {config['OUTPUT_FOLDER']}/augmentation_comparison.png")
    
    if config['SAVE_RESULTS']:
            print(f"ğŸ“Š Äá»“ thá»‹ káº¿t quáº£ episodes: {config['OUTPUT_FOLDER']}/episode_results_single.png")
    print(f"ğŸ“Š Confusion matrix: {config['OUTPUT_FOLDER']}/query_confusion_matrix.png")
    print(f"ğŸ“Š Accuracy theo class: {config['OUTPUT_FOLDER']}/query_accuracy_by_class.png")
    print(f"ğŸ“Š Classification report: {config['OUTPUT_FOLDER']}/query_classification_report.png")
    

    
    # print(f"ğŸ“Š Imbalance analysis: {config['OUTPUT_FOLDER']}/query_imbalance_analysis.png")
    
    if config['USE_VALIDATION']:
        print(f"ğŸ“Š Validation confusion matrix: {config['OUTPUT_FOLDER']}/valid_confusion_matrix.png")
        print(f"ğŸ“Š Validation accuracy theo class: {config['OUTPUT_FOLDER']}/valid_accuracy_by_class.png")
        print(f"ğŸ“Š Validation classification report: {config['OUTPUT_FOLDER']}/valid_classification_report.png")
        # print(f"ğŸ“Š Validation imbalance analysis: {config['OUTPUT_FOLDER']}/valid_imbalance_analysis.png")
    
    print(f"ğŸ§  Model: {model_info['model_name']} ({model_info['backbone']})")
    print(f"ğŸ”§ PhÆ°Æ¡ng phÃ¡p: {distance_method.upper()} ({'CÃ³ thá»ƒ há»c Ä‘Æ°á»£c' if use_learnable else 'Cá»‘ Ä‘á»‹nh'})")
    if use_learnable:
        print(f"ğŸ“ˆ Relation scores: 0-1 (cao hÆ¡n = tÆ°Æ¡ng tá»± hÆ¡n)")
    else:
        print(f"ğŸ“ˆ Euclidean similarity: 0-1 (cao hÆ¡n = tÆ°Æ¡ng tá»± hÆ¡n)")
    print(f"ğŸ”„ Data Augmentation: {'Báº¬T' if config.get('USE_AUGMENTATION', False) else 'Táº®T'} (USE_AUGMENTATION = {config.get('USE_AUGMENTATION', False)})")
    
    print("=" * 60)

if __name__ == "__main__":
    main()
